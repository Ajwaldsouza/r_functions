---
title: "NPCA Data analysis"
author: "Ajwal Dsouza"
date: "2024-05-23"
output: html_document
editor_options: 
  markdown: 
    wrap: 72
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
knitr::knit_hooks$set(purl = knitr::hook_purl, documentation = 0) # export the r code chunks into a "code-only" R script. 
```

The overall goal of this script is to measure the photosynthetic CO2
flux as $\mu mols~CO_2~m^{-2}~leaf~area~s^{-1}$ from time-series environment data
measured in a sealed growth chamber. The time-series environment data
consists of temperature (C) and CO2 (ppm) measured every minute.

In the growth chamber, CO2 is injected to reach a specific set-point
concentration (ppm). The plants in the chambers draw down the CO2
through photosynthesis. When the CO2 concentration reaches a pre-set
lower threshold, CO2 in injected back to bring the concentration to the
setpoint.

To accurately calculate the plant net photosynthetic carbon assimilation
(NPCA), we follow these given steps:

1.  Identify the injection events and remove those datapoints

2.  For the dataset that is excluded of injection events, loop through
    each row of the CO2 ppm readings and calculate the slope and rsq
    values for 30 subsequent values and save as new columns

3.  Write a function to calculate photosynthetic CO2 flux (Flux) as
    micromol CO2/m2 leaf area/s using the slopes, chamber volume (input
    manually), canopy leaf area (A, input manually) and corresponding
    measured temperature using the equation given below:

    $$
    NPCA = slope \times \frac{p} {R T} \times \frac{V} {A}
    $$

    Where, $NPCA$ is the net photosynthetic carbon assimilation in
    $\mu mols~CO_2~m^{-2}~s^{-1}$, $slope$ is the change of CO2 over
    time in ppm/min. $p$ is the atmospheric pressure (assumed 1 atm),
    *R* is the ideal gas constant (0.082 $L~ atm ~K^{-1}~mol^{-1}$), and
    *T* is the air temperature in K. *V* is the chamber volume in L, and
    *A* is the total leaf area of the whole canopy in the chamber as
    $m^{-2}$.

This script processes a dataset to identify and remove CO2 injection
events, calculates slopes and R-squared values for linear regressions on
windows of 30 data points, and finally computes the photosynthetic CO2
flux based on these slopes and additional parameters like chamber volume
and canopy leaf area.

# Initial setup

## Installing packages

Install and load all the necessary packages for this analysis using the
`librarian` package.

```{r message=FALSE, warning=FALSE, include=FALSE}
install.packages("librarian", repos='http://cran.us.r-project.org')
librarian::shelf(plyr,
                 dplyr,
                 lubridate,
                 tidyr,
                 tibble,
                 rstudioapi,
                 ggplot2,
                 ggpubr,
                 readr,
                 EnvStats,
                 quiet = TRUE,
                 update_all = FALSE)
```

## Setting working directory

Set the working directory for the project. The `setwd` line sets the
source file location of the R script as the working directory.

```{r set wd, message=FALSE, warning=FALSE}
setwd(dirname(getActiveDocumentContext()$path))                                 
```

## Importing datafiles

First, set the folder that contains the raw data files as `mydir`. Next,
we list all the files with .csv files in the specified "mydir" as
`myfiles` and call the list.

```{r label data, message=F, warning=F}
mydir="raw"
myfiles= list.files(path=mydir, pattern="*.csv", full.names=TRUE)
myfiles
```

## Importing datafiles into single dataframe

The following code imports all the .csv files in the raw data folder
into one single dataset, called `datamaster`.

```{r import data}
data_master <- ldply(myfiles, read.table, sep = ",", fill=T, header = F)%>%     #collectively apply "import" function for all the files in the specified directory
  as_tibble()%>%                                                                #Convert the imported data as a tibble
  na.omit()%>%
  select(V = c(V1,V2,V12, V13, V21))%>%
  #Rename  the columns while importing. 
  rename(time=V1, 
         temp = V2,
         light_int = V3,
         co2_read = V4,
         co2_set = V5)%>%
  slice(c(1:1440))

```

# Data Cleaning

Next, let us clean the raw data and prep it for the analysis.

## Setting the data type for each column

Setting all the columns except 1st to as numeric

```{r set numeric, message = F}
data_master[, 2:ncol(data_master)] <- 
  lapply(data_master[,2:ncol(data_master)], as.numeric)
```

Setting first column as date-time variable

```{r set date-time}
data_master$time <- as_datetime(data_master$time)   
```

## Identifying and removing injection events

In the raw file, there are injection events where CO2 is injected to
reach the CO2 setpoint, where there is a rapid rise of CO2 concentration
in a relatively short duration of time (compared to plant CO2 draw-down
rate). This can create a nuisance during the calculation of
photosynthetic flux.

### Define a threshold for detecting injection events

This line sets a threshold value 10 (10 ppm rise between subsequent
readings) for detecting significant changes (injection events) in the
`CO2` levels.

```{r set threshold for detection injection events}
threshold <- 10 
```

### Identify and remove injection events

Based on the defined threshold, identify and remove the injection events
to save the datafile as `cleaned_data`.

```{r Identify and remove injection events}
cleaned_data <- data_master %>%
  mutate(injection = if_else((co2_read - lag(
    co2_read, default = first(co2_read))) > threshold, TRUE, FALSE)) %>%
  filter(injection == FALSE) %>%
  select(-injection)

```

Here,

-   `mutate`: Adds a new column to the DataFrame.

-   `lag(CO2, default = first(CO2))`: Shifts the `CO2` column down by
    one row, filling the first value with the first value of the `CO2`
    column to handle the edge case.

-   `(CO2 - lag(CO2)) > threshold`: Calculates the difference between
    the current and the previous `CO2` value, then checks if this
    difference exceeds the threshold.

-   `if_else(..., TRUE, FALSE)`: Creates a boolean column `injection`
    that is `TRUE` if the difference exceeds the threshold and `FALSE`
    otherwise.

-   `filter(injection == FALSE)`: Filters out rows where `injection` is
    `TRUE`, keeping only rows without injection events.

-   `select(-injection)`: Removes the `injection` column from the
    DataFrame.

## Creating a minutes column

Create a new column named `minutes` with consecutive numbers starting
from zero

```{r Creating a minutes column}
cleaned_data$minutes <- seq(0, by = 1, length.out = nrow(cleaned_data))

# data_master$minutes <- data_master$minutes*10
# data_master$hours <- data_master$minutes/60

```

If the dataset with readings every minute is to be reduced to retain
reading for longer intervals (e.g., 10 mins), run the following code by
specifying the desired time interval in the command `breaks`.

```{r reduce minutes to longer intervals}
# # #Reducing the dataset by reducing sampling interval
# groups <- cut(as.POSIXct(data_master$time), breaks="10 min")
# library(plyr)
# data_master <- ddply(data_master, "groups", tail, 1)[, -1]
```

## Visualizing the raw CO2 readings

```{r plot the raw CO2 readings}
p <-
  ggplot(aes(x=time, y=co2_read), data = data_master) +
  geom_line()+ 
  labs(x="Time (hours)", y=expression(CO[2]~(ppm)), color="10:1")+
  theme_classic()+
  theme(axis.text = element_text(size = 11),
        axis.title = element_text(size = 12),
        axis.line = element_line(size = 0.4))+
  theme(legend.position = c(0.8, 0.75),
        legend.direction = "vertical",
        legend.title = element_text(size = 12),
        legend.text = element_text(size = 10))
p
```

# Calculating the net photosynthetic assimilation rate

We have to calculate the rate of change of CO2 over time in ppm/min, as
the moving slopes of the linear fits through least squares method for 30
consecutive readings.

## Calculating the rate of change of CO2 over time as slope

### Function to calculate slope and R-squared for consecutive points

First, we create a function that calculates the slope and R-squared for
consecutive points.

```{r Function to calculate slope and R-squared for consecutive points}
calc_slope_rsq <- function(x, y) {
  model <- lm(y ~ x)
  slope <- coef(model)[2]
  rsq <- summary(model)$r.squared
  return(list(slope = slope, rsq = rsq))
}
```

This function performs a linear regression on a set of points:

-   `lm(y ~ x)`: Fits a linear model.

-   `coef(model)[2]`: Extracts the slope (coefficient of `x`).

-   `summary(model)$r.squared`: Extracts the R-squared value, indicating
    how well the model fits the data.

### Apply the function to calculate slope and R-squared for each window of 30 consecutive points

```{r run slope function, message=FALSE}
cleaned_data <- cleaned_data %>%
  mutate(slope = NA, rsq = NA)

for (i in 1:(nrow(cleaned_data) - 30)) {
  result <- calc_slope_rsq(cleaned_data$minutes[i:(i + 30)], cleaned_data$co2_read[i:(i + 30)])
  cleaned_data$slope[i + 2] <- result$slope  # Center the slope value
  cleaned_data$rsq[i + 2] <- result$rsq      # Center the rsq value
}
```

-   `mutate(slope = NA, rsq = NA)`: Adds two new columns, `slope` and
    `rsq`, initialized with `NA`.

-   `for (i in 1:(nrow(cleaned_data) - 30))`: Loops through each window
    of 30 points.

-   `calc_slope_rsq(...)`: Calculates the slope and R-squared for each
    window.

-   `cleaned_data$slope[i + 2] <- result$slope`: Centers the slope value
    in the middle of the 30-point window.

-   `cleaned_data$rsq[i + 2] <- result$rsq`: Centers the R-squared value
    in the middle of the 30-point window

### Remove rows where slope and rsq could not be calculated (i.e., first and last 2 rows)

```{r remove entries without calculated slope}
cleaned_data <- cleaned_data %>%
  filter(!is.na(slope) & !is.na(rsq))
```

Filters out rows where `slope` or `rsq` are `NA`, which happens for the
first and last two rows due to the centering of values.

## Filtering low-fit datapoints

For the slopes calculated, there would be points with low rsq,
especially in places between an injection event. These are nuisance
artefacts that must be removed.

We will set our lower rsq threshold as `filter_rsq`

```{r set threshold for filtering low rsq entries}
filter_rsq <- 0.5
```

Filter the data to eliminate the readings with rsq lower than the set
threshold

```{r filter data to eliminate low rsq entries}
cleaned_data <- 
  cleaned_data%>%
  subset(rsq >= filter_rsq)
```

## Define the function to calculate photosynthetic CO2 flux

Next, we create a function `calc_flux` to calculate the net
photosynthetic carbon assimilation (NPCA) as
$\mu mols~CO_2~m^{-2}~s^{-1}$ using the ideal gas law.

```{r function to calculate NPCA}
calc_flux <- function(slope, T, V, A) {
  p <- 1  # atmospheric pressure in atm
  R <- 0.082  # ideal gas constant in L atm K−1 mol−1
  T_k <- T + 273.15  # convert temperature from Celsius to Kelvin
  
  flux <- -slope * (p / (R * T_k)) * V / A
  return(flux)
}
```

Here,

-   `p`: Atmospheric pressure (1 atm).

-   `R`: Ideal gas constant.

-   `T_k`: Converts temperature from Celsius to Kelvin.

-   `flux`: Calculates the photosynthetic CO2 flux using the given
    formula.

-   `V`: volume of the chamber (L)

-   `A`: Total leaf area of the plant canopy ($m^2$)

### Manually input the chamber volume (V) in liters and canopy leaf area (A) in $m^2$

Set the volume of the chamber and the area of the canopy, which are used
in the flux calculation.

```{r setting the chamber volumen and leaf area}
V <- 100  #  value in liters
A <- 1  #  value in m^2
```

## Apply the flux calculation to the dataset

Add a new column `flux` to `cleaned_data` by applying the `calc_flux`
function to each row.

```{r calculate the flux}
cleaned_data <- cleaned_data %>%
  mutate(flux = calc_flux(slope, temp, V, A))
```

### Visualize the NPCA derived from the processed dataset

```{r visualise the NPCA from processed data}
ggplot(aes(x=minutes, y=flux), data = cleaned_data) +
  geom_line()+ 
  labs(x="Time (hours)", y=expression(CO[2]~(ppm)))+
  theme_classic()+
  theme(axis.text = element_text(size = 11),
        axis.title = element_text(size = 12),
        axis.line = element_line(size = 0.4))+
  theme(legend.position = c(0.8, 0.75),
        legend.direction = "vertical",
        legend.title = element_text(size = 12),
        legend.text = element_text(size = 10))
```

We can use the plot to visually inspect for any anomalies or noise in
the data. As we can see in the plot, there are four drops in NPCA, which
if parsed through in the data, we find are due to the injection events.
We can eliminate these anomalies by manually filtering out these
anomalous data-points as such:

```{r remove visually determined anomalies}
npca_data <- 
  cleaned_data%>%
  subset(flux > -2)
```

I selected the flux (or NPCA) cutoff -2 based on visual inspection, and
created a final data frame called `npca_data`.

Lets plot the final data:

```{r plot final data}
ggplot(aes(x=minutes, y=flux), data = npca_data) +
  geom_line()+ 
  labs(x="Time (hours)", y=expression(CO[2]~(ppm)))+
  theme_classic()+
  theme(axis.text = element_text(size = 11),
        axis.title = element_text(size = 12),
        axis.line = element_line(size = 0.4))+
  theme(legend.position = c(0.8, 0.75),
        legend.direction = "vertical",
        legend.title = element_text(size = 12),
        legend.text = element_text(size = 10))
```

THIS LOOKS GOOD!

------------------------------------------------------------------------

# Additional Analyses

## Outlier detection and removal using Rosner's test

Perform a Rosner's test using the function `rosnerTest` from the
`EnvStat` package. Set 'k' as the maximum number of outliers to test
for. Adjust as necessary. Run the Rosner's test.

> NOTE: The Rosner's test is only appropriate when calculating only
> day-NPCA, not diurnal NPCA, which will inherently differ substantially
> from the day.

```{r}
k <- 10  # example value, adjust based on your needs
rosner_test <- EnvStats::rosnerTest(npca_data$flux, k = k)
```

### View the results of the Rosner's test

```{r}
print(rosner_test)
```

### Extract and remove the outlier indices

If there are any outliers present, we can extract and remove them from
the data. This first code extracts the outliers as identified in the
Rosner's test.

```{r}
outlier_indices <-
rosner_test$all.stats[rosner_test$all.stats$Outlier, "Index"]
```

Next, we remove the outliers from the cleaned_data

```{r eval=FALSE, include=FALSE}
npca_data_no_outliers <- npca_data[-outlier_indices, ]
```
